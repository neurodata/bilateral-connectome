{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f28a1d4",
   "metadata": {},
   "source": [
    "# Comparing methods for SBM testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3b985",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from giskard.plot import subuniformity_plot\n",
    "from matplotlib.transforms import Bbox\n",
    "from pkg.data import load_network_palette, load_node_palette, load_unmatched\n",
    "from pkg.io import FIG_PATH, get_environment_variables\n",
    "from pkg.io import glue as default_glue\n",
    "from pkg.io import savefig\n",
    "from pkg.plot import SmartSVG, set_theme\n",
    "from pkg.stats import binom_2samp, stochastic_block_test\n",
    "from scipy.stats import beta, binom, chi2\n",
    "from scipy.stats import combine_pvalues as scipy_combine_pvalues\n",
    "from scipy.stats import ks_1samp, uniform\n",
    "from svgutils.compose import Figure, Panel, Text\n",
    "\n",
    "\n",
    "_, RERUN_SIMS, DISPLAY_FIGS = get_environment_variables()\n",
    "\n",
    "\n",
    "FILENAME = \"revamp_sbm_methods_sim\"\n",
    "\n",
    "FIG_PATH = FIG_PATH / FILENAME\n",
    "\n",
    "\n",
    "def glue(name, var, **kwargs):\n",
    "    default_glue(name, var, FILENAME, **kwargs)\n",
    "\n",
    "\n",
    "def gluefig(name, fig, **kwargs):\n",
    "    savefig(name, foldername=FILENAME, **kwargs)\n",
    "\n",
    "    glue(name, fig, figure=True)\n",
    "\n",
    "    if not DISPLAY_FIGS:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "set_theme()\n",
    "rng = np.random.default_rng(8888)\n",
    "\n",
    "network_palette, NETWORK_KEY = load_network_palette()\n",
    "node_palette, NODE_KEY = load_node_palette()\n",
    "fisher_color = sns.color_palette(\"Set2\")[2]\n",
    "min_color = sns.color_palette(\"Set2\")[3]\n",
    "eric_color = sns.color_palette(\"Set2\")[4]\n",
    "\n",
    "GROUP_KEY = \"simple_group\"\n",
    "\n",
    "left_adj, left_nodes = load_unmatched(side=\"left\")\n",
    "right_adj, right_nodes = load_unmatched(side=\"right\")\n",
    "\n",
    "left_labels = left_nodes[GROUP_KEY].values\n",
    "right_labels = right_nodes[GROUP_KEY].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dcfa1",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "stat, pvalue, misc = stochastic_block_test(\n",
    "    left_adj,\n",
    "    right_adj,\n",
    "    labels1=left_labels,\n",
    "    labels2=right_labels,\n",
    "    method=\"fisher\",\n",
    "    combine_method=\"fisher\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf95fbc",
   "metadata": {},
   "source": [
    "## Model for simulations (alternative)\n",
    "We have fit a stochastic block model to the left and right hemispheres. Say the\n",
    "probabilities of group-to-group connections *on the left* are stored in the matrix\n",
    "$B$, so that $B_{kl}$ is the probability of an edge from group $k$ to $l$.\n",
    "\n",
    "Let $\\tilde{B}$ be a *perturbed* matrix of probabilities. We are interested in testing\n",
    "$H_0: B = \\tilde{B}$ vs. $H_a: ... \\neq ...$. To do so, we compare each\n",
    "$H_0: B_{kl} = \\tilde{B}_{kl}$ using Fisher's exact test. This results in p-values for\n",
    "each $(k,l)$ comparison, $\\{p_{1,1}, p_{1,2}...p_{K,K}\\}$.\n",
    "\n",
    "Now, we still are after an overall test for the equality $B = \\tilde{B}$. Thus, we\n",
    "need a way to combine p-values $\\{p_{1,1}, p_{1,2}...p_{K,K}\\}$ to get an *overall*\n",
    "p-value for our test comparing the stochastic block model probabilities. One way is\n",
    "Fisher's method; another is Tippett's method.\n",
    "\n",
    "To compare how these two alternative methods of combining p-values work, we did the\n",
    "following simulation:\n",
    "\n",
    "- Let $t$ be the number of probabilities to perturb.\n",
    "- Let $\\delta$ represent the strength of the perturbation (see model below).\n",
    "- For each trial:\n",
    "   - Randomly select $t$ probabilities without replacement from the elements of $B$\n",
    "   - For each of these elements, $\\tilde{B}_{kl} = TN(B_{kl}, \\delta B_{kl})$ where\n",
    "     $TN$ is a truncated normal distribution, such that probabilities don't end up\n",
    "     outside of [0, 1].\n",
    "   - For each element *not* perturbed, $\\tilde{B}_{kl} = B_{kl}$\n",
    "   - Sample the number of edges from each block under each model. In other words, let\n",
    "     $m_{kl}$ be the number of edges in the $(k,l)$-th block, and let $n_k, n_l$ be\n",
    "     the number of edges in the $k$-th and $l$-th blocks, respectively. Then, we have\n",
    "\n",
    "     $$m_{kl} \\sim Binomial(n_k n_l, B_{kl})$$\n",
    "\n",
    "     and likewise but with $\\tilde{B}_{kl}$ for $\\tilde{m}_{kl}$.\n",
    "   - Run Fisher's exact test to generate a $p_{kl}$ for each $(k,l)$.\n",
    "   - Run Fisher's or Tippett's method for combining p-values\n",
    "- These trials were repeated for $\\delta \\in \\{0.1, 0.2, 0.3, 0.4, 0.5\\}$ and\n",
    "$t \\in \\{25, 50, 75, 100, 125\\}$. For each $(\\delta, t)$ we ran 100 replicates of the\n",
    "model/test above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36743907",
   "metadata": {},
   "source": [
    "## P-values under the null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9dcf5d",
   "metadata": {},
   "source": [
    "```{glue:figure} fig:revamp_sbm_methods_sim-null_distributions\n",
    "\n",
    "Distributions of p-values under the null for each method. Dotted line indicates\n",
    "the CDF of a $Uniform(0,1)$ random variable. The\n",
    "p-values in the upper left of each panel is for a 1-sample KS test, where the null is\n",
    "that the variable is distributed $Uniform(0,1)$ against the alternative that its CDF\n",
    "is larger than that of a $Uniform(0,1)$ random variable (i.e. that it is superuniform).\n",
    "Note that all methods appear empirically valid, some appear highly conservative.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10248c87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## P-values under the alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348a5b2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_shift_pvalues(pvalues, rng=None):\n",
    "    pvalues = np.sort(pvalues)  # already makes a copy\n",
    "    diffs = list(pvalues[1:] - pvalues[:-1])\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    uniform_samples = rng.uniform(size=len(diffs))\n",
    "    moves = uniform_samples * diffs\n",
    "    pvalues[1:] = pvalues[1:] - moves\n",
    "    return pvalues\n",
    "\n",
    "\n",
    "def my_combine_pvalues(pvalues, method=\"fisher\", pad_high=0, n_resamples=100):\n",
    "    pvalues = np.array(pvalues)\n",
    "    # some methods use log(1 - pvalue) as part of the test statistic - thus when pvalue\n",
    "    # is exactly 1 (which is possible for Fisher's exact test) we get an underfined\n",
    "    # answer.\n",
    "    if pad_high > 0:\n",
    "        upper_lim = 1 - pad_high\n",
    "        pvalues[pvalues >= upper_lim] = upper_lim\n",
    "\n",
    "    scipy_methods = [\"fisher\", \"pearson\", \"tippett\", \"stouffer\", \"mudholkar_george\"]\n",
    "\n",
    "    if method == \"fisher-discrete-random\":\n",
    "        stat = 0\n",
    "        pvalue = 0\n",
    "        shifted_pvalues = []\n",
    "        for i in range(n_resamples):\n",
    "            shifted_pvalues = random_shift_pvalues(pvalues)\n",
    "            curr_stat, curr_pvalue = scipy_combine_pvalues(\n",
    "                shifted_pvalues, method=\"fisher\"\n",
    "            )\n",
    "            stat += curr_stat / n_resamples\n",
    "            pvalue += curr_pvalue / n_resamples\n",
    "    elif method == \"pearson\":  # HACK: https://github.com/scipy/scipy/pull/15452\n",
    "        stat = 2 * np.sum(np.log1p(-pvalues))\n",
    "        pvalue = chi2.cdf(-stat, 2 * len(pvalues))\n",
    "    elif method == \"tippett\":\n",
    "        stat = np.min(pvalues)\n",
    "        pvalue = beta.cdf(stat, 1, len(pvalues))\n",
    "    elif method in scipy_methods:\n",
    "        stat, pvalue = scipy_combine_pvalues(pvalues, method=method)\n",
    "    elif method == \"eric\":\n",
    "        stat, pvalue = ks_1samp(pvalues, uniform(0, 1).cdf, alternative=\"greater\")\n",
    "    elif method == \"min\":\n",
    "        pvalue = min(pvalues.min() * len(pvalues), 1)\n",
    "        stat = pvalue\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return stat, pvalue\n",
    "\n",
    "\n",
    "def bootstrap_sample(counts, n_possible):\n",
    "    probs = counts / n_possible\n",
    "    return binom.rvs(n_possible, probs)\n",
    "\n",
    "\n",
    "def compute_test_statistic(\n",
    "    counts1, n_possible1, counts2, n_possible2, statistic=\"norm\"\n",
    "):\n",
    "    probs1 = counts1 / n_possible1\n",
    "    probs2 = counts2 / n_possible2\n",
    "    if statistic == \"norm\":\n",
    "        stat = np.linalg.norm(probs1 - probs2)\n",
    "    elif statistic == \"max\":\n",
    "        stat = np.max(np.abs(probs1 - probs2))\n",
    "    elif statistic == \"abs\":\n",
    "        stat = np.linalg.norm(probs1 - probs2, ord=1)\n",
    "    return stat\n",
    "\n",
    "\n",
    "def bootstrap_test(counts1, n_possible1, counts2, n_possible2, n_bootstraps=200):\n",
    "    counts1 = np.array(counts1)\n",
    "    n_possible1 = np.array(n_possible1)\n",
    "    counts2 = np.array(counts2)\n",
    "    n_possible2 = np.array(n_possible2)\n",
    "\n",
    "    stat = compute_test_statistic(counts1, n_possible1, counts2, n_possible2)\n",
    "\n",
    "    pooled_counts = (counts1 + counts2) / 2\n",
    "    pooled_n_possible = (n_possible1 + n_possible2) / 2  # roughly correct?\n",
    "    pooled_n_possible = pooled_n_possible.astype(int)\n",
    "    null_stats = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # TODO I think these should use the slightly different counts here actually\n",
    "        bootstrap_counts1 = bootstrap_sample(pooled_counts, pooled_n_possible)\n",
    "        bootstrap_counts2 = bootstrap_sample(pooled_counts, pooled_n_possible)\n",
    "        null_stat = compute_test_statistic(\n",
    "            bootstrap_counts1, pooled_n_possible, bootstrap_counts2, pooled_n_possible\n",
    "        )\n",
    "        null_stats.append(null_stat)\n",
    "    null_stats = np.sort(null_stats)\n",
    "\n",
    "    pvalue = (1 + (null_stats >= stat).sum()) / (1 + n_bootstraps)\n",
    "\n",
    "    misc = {}\n",
    "\n",
    "    return stat, pvalue, misc\n",
    "\n",
    "\n",
    "def compare_individual_probabilities(counts1, n_possible1, counts2, n_possible2):\n",
    "    pvalue_collection = []\n",
    "    for i in range(len(counts1)):\n",
    "        sub_stat, sub_pvalue = binom_2samp(\n",
    "            counts1[i],\n",
    "            n_possible1[i],\n",
    "            counts2[i],\n",
    "            n_possible2[i],\n",
    "            null_odds=1,\n",
    "            method=\"fisher\",\n",
    "        )\n",
    "        pvalue_collection.append(sub_pvalue)\n",
    "\n",
    "    pvalue_collection = np.array(pvalue_collection)\n",
    "    pvalue_collection = pvalue_collection[~np.isnan(pvalue_collection)]\n",
    "    return pvalue_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e980c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "save_path = Path(\n",
    "    \"/Users/bpedigo/JHU_code/bilateral/bilateral-connectome/results/\"\n",
    "    f\"outputs/{FILENAME}/results.csv\"\n",
    ")\n",
    "uncorrected_pvalue_path = Path(\n",
    "    \"/Users/bpedigo/JHU_code/bilateral/bilateral-connectome/results/\"\n",
    "    f\"outputs/{FILENAME}/uncorrected_pvalues.csv\"\n",
    ")\n",
    "\n",
    "fieldnames = [\n",
    "    \"perturb_size\",\n",
    "    \"n_perturb\",\n",
    "    \"sim\",\n",
    "    \"uncorrected_pvalues\",\n",
    "]\n",
    "\n",
    "combine_methods = [\n",
    "    \"fisher\",\n",
    "    \"pearson\",\n",
    "    \"tippett\",\n",
    "    \"stouffer\",\n",
    "    \"mudholkar_george\",\n",
    "    \"min\",\n",
    "]\n",
    "bootstrap_methods = [\"bootstrap-norm\", \"bootstrap-max\", \"bootstrap-abs\"]\n",
    "methods = combine_methods + bootstrap_methods\n",
    "\n",
    "B_base = misc[\"probabilities1\"].values\n",
    "inds = np.nonzero(B_base)\n",
    "base_probs = B_base[inds]\n",
    "n_possible_matrix = misc[\"possible1\"].values\n",
    "ns = n_possible_matrix[inds]\n",
    "\n",
    "# n_null_sims = 100\n",
    "n_bootstraps = 1000\n",
    "n_sims = 50\n",
    "n_perturb_range = np.linspace(0, 125, 6, dtype=int)\n",
    "perturb_size_range = np.round(np.linspace(0, 0.5, 6), decimals=3)\n",
    "print(f\"Perturb sizes: {perturb_size_range}\")\n",
    "print(f\"Perturb number range: {n_perturb_range}\")\n",
    "n_runs = n_sims * len(n_perturb_range) * len(perturb_size_range)\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "\n",
    "\n",
    "if RERUN_SIMS:\n",
    "    t0 = time.time()\n",
    "    mean_itertimes = 0\n",
    "    n_time_first = 5\n",
    "    progress_steps = 0.05\n",
    "    progress_counter = 0\n",
    "    last_progress = -0.05\n",
    "    rows = []\n",
    "    example_perturb_probs = {}\n",
    "\n",
    "    with open(uncorrected_pvalue_path, \"w\") as f:\n",
    "        f.truncate()\n",
    "\n",
    "    with open(uncorrected_pvalue_path, \"a\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "    for perturb_size in perturb_size_range:\n",
    "        for n_perturb in n_perturb_range:\n",
    "            # if (perturb_size == 0) or (n_perturb == 0):\n",
    "            for sim in range(n_sims):\n",
    "                itertime = time.time()\n",
    "\n",
    "                # just a way to track progress\n",
    "                progress_counter += 1\n",
    "                progress_prop = progress_counter / n_runs\n",
    "                if progress_prop - progress_steps > last_progress:\n",
    "                    print(f\"{progress_prop:.2f}\")\n",
    "                    last_progress = progress_prop\n",
    "\n",
    "                # choose some elements to perturb\n",
    "                perturb_probs = base_probs.copy()\n",
    "                choice_indices = rng.choice(\n",
    "                    len(perturb_probs), size=n_perturb, replace=False\n",
    "                )\n",
    "\n",
    "                # pertub em\n",
    "                for index in choice_indices:\n",
    "                    prob = base_probs[index]\n",
    "\n",
    "                    new_prob = -1\n",
    "                    while new_prob <= 0 or new_prob >= 1:\n",
    "                        new_prob = rng.normal(prob, scale=prob * perturb_size)\n",
    "\n",
    "                    perturb_probs[index] = new_prob\n",
    "\n",
    "                # store some of the perturbed ones as examples\n",
    "                if sim == 0:\n",
    "                    example_perturb_probs[(perturb_size, n_perturb)] = perturb_probs\n",
    "\n",
    "                # sample some new binomial data\n",
    "                base_samples = binom.rvs(ns, base_probs)\n",
    "                perturb_samples = binom.rvs(ns, perturb_probs)\n",
    "\n",
    "                pvalue_collection = compare_individual_probabilities(\n",
    "                    base_samples, ns, perturb_samples, ns\n",
    "                )\n",
    "\n",
    "                pvalue_row = {\n",
    "                    \"perturb_size\": perturb_size,\n",
    "                    \"n_perturb\": n_perturb,\n",
    "                    \"sim\": sim,\n",
    "                    \"uncorrected_pvalues\": list(pvalue_collection),\n",
    "                }\n",
    "\n",
    "                with open(uncorrected_pvalue_path, \"a\") as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames)\n",
    "                    writer.writerow(pvalue_row)\n",
    "\n",
    "                for method in methods:\n",
    "                    if method in combine_methods:\n",
    "                        stat, pvalue = my_combine_pvalues(\n",
    "                            pvalue_collection, method=method\n",
    "                        )\n",
    "                    elif method in bootstrap_methods:\n",
    "                        stat, pvalue, _ = bootstrap_test(\n",
    "                            base_samples,\n",
    "                            ns,\n",
    "                            perturb_samples,\n",
    "                            ns,\n",
    "                            n_bootstraps=n_bootstraps,\n",
    "                        )\n",
    "                    row = {\n",
    "                        \"perturb_size\": perturb_size,\n",
    "                        \"n_perturb\": n_perturb,\n",
    "                        \"sim\": sim,\n",
    "                        \"stat\": stat,\n",
    "                        \"pvalue\": pvalue,\n",
    "                        \"method\": method,\n",
    "                    }\n",
    "                    rows.append(row)\n",
    "\n",
    "                if progress_counter < n_time_first:\n",
    "                    iter_elapsed = time.time() - itertime\n",
    "                    mean_itertimes += iter_elapsed / n_time_first\n",
    "                elif progress_counter == n_time_first:\n",
    "                    projected_time = mean_itertimes * n_runs\n",
    "                    projected_time = datetime.timedelta(seconds=projected_time)\n",
    "                    print(\"---\")\n",
    "                    print(f\"Projected time: {projected_time}\")\n",
    "                    print(\"---\")\n",
    "\n",
    "    total_elapsed = time.time() - t0\n",
    "\n",
    "    print(\"Done!\")\n",
    "    print(f\"Total experiment took: {datetime.timedelta(seconds=total_elapsed)}\")\n",
    "    results = pd.DataFrame(rows)\n",
    "    results.to_csv(save_path)\n",
    "else:\n",
    "    results = pd.read_csv(save_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65420502",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "method_palette = dict(zip(methods, sns.color_palette()))\n",
    "\n",
    "null_results = results[(results[\"n_perturb\"] == 0) | (results[\"perturb_size\"] == 0)]\n",
    "\n",
    "n_methods = len(methods)\n",
    "n_cols = min(n_methods, 3)\n",
    "n_rows = int(np.ceil(n_methods / n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, squeeze=False, figsize=(n_cols * 5, n_rows * 5))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axs.flat[i]\n",
    "    method_null_results = null_results[null_results[\"method\"] == method]\n",
    "    subuniformity_plot(\n",
    "        method_null_results[\"pvalue\"],\n",
    "        ax=ax,\n",
    "        color=method_palette[method],\n",
    "        bins=np.linspace(0, 1, 100),\n",
    "    )\n",
    "    ax.set_title(method.capitalize())\n",
    "plt.tight_layout()\n",
    "gluefig(\"null_distributions\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f1488",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if RERUN_SIMS:\n",
    "    fig, axs = plt.subplots(\n",
    "        len(perturb_size_range), len(n_perturb_range), figsize=(20, 20), sharey=True\n",
    "    )\n",
    "\n",
    "    for i, perturb_size in enumerate(perturb_size_range):\n",
    "        for j, n_perturb in enumerate(n_perturb_range):\n",
    "            ax = axs[i, j]\n",
    "            perturb_probs = example_perturb_probs[(perturb_size, n_perturb)]\n",
    "            mask = base_probs != perturb_probs\n",
    "            show_base_probs = base_probs[mask]\n",
    "            show_perturb_probs = perturb_probs[mask]\n",
    "            sort_inds = np.argsort(-show_base_probs)\n",
    "            show_base_probs = show_base_probs[sort_inds]\n",
    "            show_perturb_probs = show_perturb_probs[sort_inds]\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=np.arange(len(show_base_probs)), y=show_perturb_probs, ax=ax, s=10\n",
    "            )\n",
    "            sns.lineplot(\n",
    "                x=np.arange(len(show_base_probs)),\n",
    "                y=show_base_probs,\n",
    "                ax=ax,\n",
    "                linewidth=1,\n",
    "                zorder=-1,\n",
    "                color=\"orange\",\n",
    "            )\n",
    "            ax.set(xticks=[])\n",
    "\n",
    "    ax.set(yscale=\"log\")\n",
    "\n",
    "    gluefig(\"example_perturbations\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d86262",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "lower = 1e-20\n",
    "for i, perturb_size in enumerate(perturb_size_range[1:]):\n",
    "    ax = axs.flat[i]\n",
    "    plot_results = results[results[\"perturb_size\"] == perturb_size]\n",
    "    sns.lineplot(\n",
    "        data=plot_results,\n",
    "        x=\"n_perturb\",\n",
    "        y=\"pvalue\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        palette=method_palette,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(yscale=\"log\")\n",
    "    ax.get_legend().remove()\n",
    "    ax.axhline(0.05, color=\"dimgrey\", linestyle=\":\")\n",
    "    ax.axhline(0.005, color=\"dimgrey\", linestyle=\"--\")\n",
    "    ax.set(ylabel=\"\", xlabel=\"\", title=f\"{perturb_size}\")\n",
    "    ylim = ax.get_ylim()\n",
    "    if ylim[0] < lower:\n",
    "        ax.set_ylim((lower, 1.05))\n",
    "    else:\n",
    "        ax.set_ylim((ylim[0], 1.05))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "ax.annotate(\n",
    "    0.05,\n",
    "    xy=(ax.get_xlim()[1], 0.05),\n",
    "    xytext=(30, 10),\n",
    "    textcoords=\"offset points\",\n",
    "    arrowprops=dict(arrowstyle=\"-\"),\n",
    ")\n",
    "ax.annotate(\n",
    "    0.005,\n",
    "    xy=(ax.get_xlim()[1], 0.005),\n",
    "    xytext=(30, -40),\n",
    "    textcoords=\"offset points\",\n",
    "    arrowprops=dict(arrowstyle=\"-\"),\n",
    ")\n",
    "axs.flat[-1].axis(\"off\")\n",
    "\n",
    "[ax.set(ylabel=\"p-value\") for ax in axs[:, 0]]\n",
    "[ax.set(xlabel=\"Number perturbed\") for ax in axs[1, :]]\n",
    "axs[0, -1].set(xlabel=\"Number perturbed\")\n",
    "\n",
    "axs[0, 0].set_title(f\"Perturbation size = {perturb_size_range[1]}\")\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    labels[i] = label.capitalize()\n",
    "axs.flat[-1].legend(handles=handles, labels=labels, title=\"Method\")\n",
    "\n",
    "gluefig(\"perturbation_pvalues_lineplots\", fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bacdb2",
   "metadata": {},
   "source": [
    "```{glue:figure} fig:revamp_sbm_methods_sim-perturbation_pvalues_lineplots\n",
    "\n",
    "p-values under the alternative for two different methods for combining p-values:\n",
    "[**Fisher's method**](https://en.wikipedia.org/wiki/Fisher%27s_method) (performed on the\n",
    "*uncorrected* p-values) and Tippett's method.\n",
    "The alternative is specified by changing the number of probabilities which are perturbed\n",
    "(x-axis in each panel) as well as the size of the perturbations which are done\n",
    "to each probability (panels show increasing perturbation size). Dotted and dashed\n",
    "lines indicate significance thresholds for $\\alpha = \\{0.05, 0.005\\}$, respectively.\n",
    "Note that in this simulation, even for large numbers of small perturbations (i.e. upper\n",
    "left panel), Tippett's method has smaller p-values. Fisher's method displays smaller p-values\n",
    "than Tippett's only when there are many (>50) large perturbations, but by this point both\n",
    "methods yield extremely small p-values.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c43b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Power under the alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4980a54",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "results[\"detected\"] = 0\n",
    "results.loc[results[(results[\"pvalue\"] < alpha)].index, \"detected\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73820dec",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fisher_results = results[results[\"method\"] == \"fisher\"]\n",
    "min_results = results[results[\"method\"] == \"tippett\"]\n",
    "\n",
    "fisher_means = fisher_results.groupby([\"perturb_size\", \"n_perturb\"]).mean()\n",
    "min_means = min_results.groupby([\"perturb_size\", \"n_perturb\"]).mean()\n",
    "\n",
    "fisher_power_square = fisher_means.reset_index().pivot(\n",
    "    index=\"perturb_size\", columns=\"n_perturb\", values=\"detected\"\n",
    ")\n",
    "min_power_square = min_means.reset_index().pivot(\n",
    "    index=\"perturb_size\", columns=\"n_perturb\", values=\"detected\"\n",
    ")\n",
    "\n",
    "mean_diffs = fisher_means[\"detected\"] / min_means[\"detected\"]\n",
    "\n",
    "mean_diffs = mean_diffs.to_frame().reset_index()\n",
    "\n",
    "ratios_square = mean_diffs.pivot(\n",
    "    index=\"perturb_size\", columns=\"n_perturb\", values=\"detected\"\n",
    ")\n",
    "\n",
    "v = np.max(np.abs(mean_diffs.values))\n",
    "\n",
    "set_theme(font_scale=1.5)\n",
    "# set up plot\n",
    "pad = 0.5\n",
    "width_ratios = [1, pad * 1.2, 10, pad, 10, 1.3 * pad, 10, 1]\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    len(width_ratios),\n",
    "    figsize=(30, 10),\n",
    "    gridspec_kw=dict(\n",
    "        width_ratios=width_ratios,\n",
    "    ),\n",
    ")\n",
    "fisher_col = 2\n",
    "min_col = 4\n",
    "ratio_col = 6\n",
    "\n",
    "\n",
    "def shrink_axis(ax, scale=0.7):\n",
    "    pos = ax.get_position()\n",
    "    mid = (pos.ymax + pos.ymin) / 2\n",
    "    height = pos.ymax - pos.ymin\n",
    "    new_pos = Bbox(\n",
    "        [\n",
    "            [pos.xmin, mid - scale * 0.5 * height],\n",
    "            [pos.xmax, mid + scale * 0.5 * height],\n",
    "        ]\n",
    "    )\n",
    "    ax.set_position(new_pos)\n",
    "\n",
    "\n",
    "def power_heatmap(\n",
    "    data, ax=None, center=0, vmin=0, vmax=1, cmap=\"RdBu_r\", cbar=False, **kwargs\n",
    "):\n",
    "    out = sns.heatmap(\n",
    "        data.values[1:, 1:],\n",
    "        ax=ax,\n",
    "        yticklabels=perturb_size_range[1:],\n",
    "        xticklabels=n_perturb_range[1:],\n",
    "        square=True,\n",
    "        center=center,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cbar_kws=dict(shrink=0.7),\n",
    "        cbar=cbar,\n",
    "        cmap=cmap,\n",
    "        **kwargs,\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    return out\n",
    "\n",
    "\n",
    "ax = axs[fisher_col]\n",
    "im = power_heatmap(fisher_power_square, ax=ax)\n",
    "ax.set_title(\"Fisher's method\", fontsize=\"large\")\n",
    "\n",
    "ax = axs[0]\n",
    "shrink_axis(ax, scale=0.5)\n",
    "_ = fig.colorbar(\n",
    "    im.get_children()[0],\n",
    "    cax=ax,\n",
    "    fraction=1,\n",
    "    shrink=1,\n",
    "    ticklocation=\"left\",\n",
    ")\n",
    "ax.set_title(\"Power\\n\" + r\"($\\alpha=0.05$)\", pad=25)\n",
    "\n",
    "ax = axs[min_col]\n",
    "power_heatmap(min_power_square, ax=ax)\n",
    "ax.set_title(\"Tippett's method\", fontsize=\"large\")\n",
    "ax.set(yticks=[])\n",
    "\n",
    "pal = sns.diverging_palette(145, 300, s=60, as_cmap=True)\n",
    "\n",
    "ax = axs[ratio_col]\n",
    "im = power_heatmap(np.log10(ratios_square), ax=ax, vmin=-2, vmax=2, center=0, cmap=pal)\n",
    "ax.set(yticks=[])\n",
    "\n",
    "ax = axs[-1]\n",
    "shrink_axis(ax, scale=0.5)\n",
    "_ = fig.colorbar(\n",
    "    im.get_children()[0],\n",
    "    cax=ax,\n",
    "    fraction=1,\n",
    "    shrink=1,\n",
    "    ticklocation=\"right\",\n",
    ")\n",
    "ax.text(2, 1, \"Fisher more\\nsensitive\", transform=ax.transAxes, va=\"top\")\n",
    "ax.text(2, 0.5, \"Equal power\", transform=ax.transAxes, va=\"center\")\n",
    "ax.text(2, 0, \"Tippett's more\\nsensitive\", transform=ax.transAxes, va=\"bottom\")\n",
    "ax.set_title(\"Log10\\npower\\nratio\", pad=20)\n",
    "\n",
    "# remove dummy axes\n",
    "for i in range(len(width_ratios)):\n",
    "    if not axs[i].has_data():\n",
    "        axs[i].set_visible(False)\n",
    "\n",
    "xlabel = r\"# perturbed blocks $\\rightarrow$\"\n",
    "ylabel = r\"Perturbation size $\\rightarrow$\"\n",
    "axs[fisher_col].set(\n",
    "    xlabel=xlabel,\n",
    "    ylabel=ylabel,\n",
    ")\n",
    "axs[min_col].set(xlabel=xlabel, ylabel=\"\")\n",
    "axs[ratio_col].set(xlabel=xlabel, ylabel=\"\")\n",
    "\n",
    "fig.text(0.09, 0.86, \"A)\", fontweight=\"bold\", fontsize=50)\n",
    "fig.text(0.64, 0.86, \"B)\", fontweight=\"bold\", fontsize=50)\n",
    "gluefig(\"relative_power\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef60d6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "set_theme(font_scale=1.25)\n",
    "\n",
    "\n",
    "min_null_results = min_results[\n",
    "    (min_results[\"n_perturb\"] == 0) | (min_results[\"perturb_size\"] == 0)\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "subuniformity_plot(min_null_results[\"pvalue\"], ax=ax, write_pvalue=False)\n",
    "ax.set_xlabel(\"p-value\")\n",
    "ax.set(title=\"p-values under $H_0$\")\n",
    "gluefig(\"tippett_null_cdf\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c1c9b",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "out = power_heatmap(min_power_square, ax=ax, cbar=True)\n",
    "xlabel = r\"# perturbed blocks $(t)$ $\\rightarrow$\"\n",
    "ylabel = r\"Perturbation size $(\\delta)$ $\\rightarrow$\"\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel, title=\"Power under $H_A $\" + r\"($\\alpha=0.05$)\")\n",
    "gluefig(\"tippett_power_matrix\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ff52f",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "fontsize = 12\n",
    "\n",
    "null = SmartSVG(FIG_PATH / \"tippett_null_cdf.svg\")\n",
    "null.set_width(200)\n",
    "null.move(10, 10)\n",
    "null_panel = Panel(null, Text(\"A)\", 5, 10, size=fontsize, weight=\"bold\"))\n",
    "\n",
    "power = SmartSVG(FIG_PATH / \"tippett_power_matrix.svg\")\n",
    "power.set_width(200)\n",
    "power.move(20, 20)\n",
    "power_panel = Panel(power, Text(\"B)\", 5, 10, size=fontsize, weight=\"bold\"))\n",
    "power_panel.move(null.width * 0.9, 0)\n",
    "\n",
    "fig = Figure(null.width * 2 * 0.9, null.width * 0.9, null_panel, power_panel)\n",
    "fig.save(FIG_PATH / \"tippett_sim_composite.svg\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501d047",
   "metadata": {},
   "source": [
    "```{glue:figure} fig:revamp_sbm_methods_sim-relative_power\n",
    "\n",
    "Comparison of power for Fisher's and Tippett's method. **A)** The power under the\n",
    "alternative described in the text for both Fisher's method and Tippett's method. In both\n",
    "heatmaps, the x-axis represents an increasing number of blocks which are perturbed,\n",
    "and the y-axis represents an increasing magnitude for each perturbation. **B)** The\n",
    "log of the ratio of powers (Fisher's / Tippett's) for each alternative. Note that positive\n",
    "(purple) values would represent that Fisher's is more powerful, and negative (green)\n",
    "represent that Tippett's method is more powerful. Notice that Tippett's method appears\n",
    "to have more power for subtler (fewer or smaller perturbations) alternatives, and\n",
    "nearly equal power for more obvious alternatives.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
