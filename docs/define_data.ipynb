{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a432e74b",
   "metadata": {},
   "source": [
    "# Larval *Drosophila melanogaster* brain connectome\n",
    "\n",
    "Recently, authors mapped a connectome of a *Drosophila melanogaster* larva. This\n",
    "synaptic wiring diagram is comprised of 3,013 neurons and over 544,000\n",
    "synapses. Importantly, this work yielded a complete reconstruction of both the left\n",
    "and right hemispheres of the brain. We can represent this data as a network, with\n",
    "nodes representing neurons and\n",
    "edges representing some number of synapses between them.\n",
    "Since there are many modeling choices to make even when deciding how to take a raw\n",
    "connectome and generate a network representation from it, we describe some of these\n",
    "choices below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd09c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Unmatched data\n",
    "First we consider a left/right hemisphere dataset which does not require any\n",
    "neuron-to-neuron correspondence between the two hemispheres.\n",
    "\n",
    "We remove all neurons who do not have at least 3 inputs and at least 3 outputs in the\n",
    "brain network - these are mostly \"young\" neurons. We then take the largest connected\n",
    "component after this removal.\n",
    "\n",
    "Then, for the networks we are going to compare, we select only the left-to-left\n",
    "(ipsilateral) induced subgraph, and likewise for the right-to-right. Note that there\n",
    "are conceivable ways to define a notion of bilateral symmetry which does include the\n",
    "contralateral connections as well, but we do not consider that here.\n",
    "\n",
    "For the networks themselves, we chose to operate on networks which are:\n",
    "- **Unweighted**: we do not consider the number of synapses between two neurons in the\n",
    "  current analysis. For the current network of\n",
    "  interest, four edge types are available: axo-axonic, axo-dendritic,\n",
    "  dendro-dendritic, and dendro-axonic. We make no distinction between these four edges\n",
    "  types. For now, we consider there to be an edge if there is at least one\n",
    "  synapse between any two neurons (of any edge type).  One could consider notions of\n",
    "  bilateral symmetry\n",
    "  for a weighted network, and even for the unweighted case, one could consider varying\n",
    "  thresholds of the network based on varying edge weights (which have often been\n",
    "  employed in connectomics studies). For now, we focus on the unweighted case purely\n",
    "  for simplicity and the availability of more two-sample tests for unweighted\n",
    "  networks,\n",
    "  though the weighted case or choice of threshold are also of great interest.\n",
    "- **Directed**: we allow for a distinction between edges which go from neuron $i$ to\n",
    "  neuron $j$ as opposed to from $j$ to $i$.\n",
    "- **Loopless**: we remove any edges which go from neuron $i$ to neuron $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30029d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:06.639685Z",
     "iopub.status.busy": "2022-04-13T20:39:06.638936Z",
     "iopub.status.idle": "2022-04-13T20:39:13.092392Z",
     "shell.execute_reply": "2022-04-13T20:39:13.092824Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2021-05-24-v2\n"
     ]
    }
   ],
   "source": [
    "from pkg.utils import set_warnings\n",
    "\n",
    "set_warnings()\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graspologic.utils import binarize, remove_loops\n",
    "from pkg.io import glue as default_glue\n",
    "from pkg.data import DATA_VERSION, load_maggot_graph, select_nice_nodes\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "FILENAME = \"define_data\"\n",
    "\n",
    "\n",
    "def glue(name, var, **kwargs):\n",
    "    default_glue(name, var, FILENAME, display=False, **kwargs)\n",
    "\n",
    "\n",
    "RESAVE = True\n",
    "\n",
    "print(f\"Using data from {DATA_VERSION}\")\n",
    "os.chdir(\"/Users/bpedigo/JHU_code/bilateral\")  # TODO fix, make this less fragile\n",
    "output_dir = os.path.join(os.getcwd(), \"bilateral-connectome/data/processed-v2\")\n",
    "output_dir = Path(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d26bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:13.101597Z",
     "iopub.status.busy": "2022-04-13T20:39:13.100986Z",
     "iopub.status.idle": "2022-04-13T20:39:35.866314Z",
     "shell.execute_reply": "2022-04-13T20:39:35.866789Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before anything: 3586\n",
      "After filter by groups to consider for paper: 3022\n",
      "After removing non left/right: 3020\n",
      "After largest connected component: 3008\n",
      "After taking largest connected component of each side 3006\n"
     ]
    }
   ],
   "source": [
    "mg = load_maggot_graph()\n",
    "\n",
    "# Used to be in \"select_nice_nodes()\"\n",
    "print(f\"Before anything: {len(mg)}\")\n",
    "mg = mg[mg.nodes[\"paper_clustered_neurons\"] | mg.nodes[\"accessory_neurons\"]]\n",
    "print(f\"After filter by groups to consider for paper: {len(mg)}\")\n",
    "mg = mg[mg.nodes[\"hemisphere\"].isin([\"L\", \"R\"])]\n",
    "print(f\"After removing non left/right: {len(mg)}\")\n",
    "mg.to_largest_connected_component(verbose=False)\n",
    "print(f\"After largest connected component: {len(mg)}\")\n",
    "# out_degrees = np.count_nonzero(mg.sum.adj, axis=0)\n",
    "# in_degrees = np.count_nonzero(mg.sum.adj, axis=1)\n",
    "# max_in_out_degree = np.maximum(out_degrees, in_degrees)\n",
    "# keep_inds = np.arange(len(mg.nodes))[max_in_out_degree > 2]\n",
    "# remove_ids = np.setdiff1d(mg.nodes.index, mg.nodes.index[keep_inds])\n",
    "# print(mg.nodes.loc[remove_ids])\n",
    "# mg.nodes = mg.nodes.iloc[keep_inds]\n",
    "# mg.g.remove_nodes_from(remove_ids)\n",
    "# print(f\"After removing weakly connected nodes: {len(mg)}\")\n",
    "# mg.to_largest_connected_component(verbose=False)\n",
    "# print(f\"After taking largest connected component again: {len(mg)}\")\n",
    "mg.nodes.sort_values(\"hemisphere\", inplace=True)\n",
    "mg.nodes[\"_inds\"] = range(len(mg.nodes))\n",
    "\n",
    "left_mg, right_mg = mg.bisect(lcc=True)\n",
    "left_nodes = left_mg.nodes\n",
    "right_nodes = right_mg.nodes\n",
    "print(\n",
    "    f\"After taking largest connected component of each side {len(left_nodes) + len(right_nodes)}\"\n",
    ")\n",
    "\n",
    "left_adj = left_mg.sum.adj\n",
    "right_adj = right_mg.sum.adj\n",
    "\n",
    "# left_adj = binarize(left_adj)\n",
    "# right_adj = binarize(right_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9f3f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:35.871784Z",
     "iopub.status.busy": "2022-04-13T20:39:35.871138Z",
     "iopub.status.idle": "2022-04-13T20:39:35.936096Z",
     "shell.execute_reply": "2022-04-13T20:39:35.936502Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.17498336660013306"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-p_loops"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.0069426112665645955"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-p_loops_edges"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "left_n_loops = np.count_nonzero(np.diag(left_adj))\n",
    "right_n_loops = np.count_nonzero(np.diag(right_adj))\n",
    "left_n_edges = np.count_nonzero(left_adj)\n",
    "right_n_edges = np.count_nonzero(right_adj)\n",
    "p_loops = (left_n_loops + right_n_loops) / (len(left_adj) + len(right_adj))\n",
    "p_loop_edges = (left_n_loops + right_n_loops) / (left_n_edges + right_n_edges)\n",
    "glue(\"p_loops\", p_loops)\n",
    "glue(\"p_loops_edges\", p_loop_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00697db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:35.940484Z",
     "iopub.status.busy": "2022-04-13T20:39:35.939882Z",
     "iopub.status.idle": "2022-04-13T20:39:36.031298Z",
     "shell.execute_reply": "2022-04-13T20:39:36.031835Z"
    },
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "1504"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-n_left_unmatched"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "1502"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-n_right_unmatched"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "left_adj = remove_loops(left_adj)\n",
    "right_adj = remove_loops(right_adj)\n",
    "\n",
    "n_left_unmatched = left_adj.shape[0]\n",
    "n_right_unmatched = right_adj.shape[0]\n",
    "glue(\"n_left_unmatched\", n_left_unmatched)\n",
    "glue(\"n_right_unmatched\", n_right_unmatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411e8d4",
   "metadata": {},
   "source": [
    "After this data cleaning, we are left with {glue:text}`n_left_unmatched` neurons in\n",
    "the left\n",
    "hemisphere, and {glue:text}`n_right_unmatched` neurons in the right hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577c32dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:36.037807Z",
     "iopub.status.busy": "2022-04-13T20:39:36.037089Z",
     "iopub.status.idle": "2022-04-13T20:39:36.862704Z",
     "shell.execute_reply": "2022-04-13T20:39:36.863119Z"
    },
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "left_adj = pd.DataFrame(\n",
    "    data=left_adj.astype(int), index=left_nodes.index, columns=left_nodes.index\n",
    ")\n",
    "left_g = nx.from_pandas_adjacency(left_adj, create_using=nx.DiGraph)\n",
    "\n",
    "if RESAVE:\n",
    "    nx.write_edgelist(\n",
    "        left_g,\n",
    "        output_dir / \"unmatched_left_edgelist.csv\",\n",
    "        delimiter=\",\",\n",
    "        data=[\"weight\"],\n",
    "    )\n",
    "    left_nodes.to_csv(output_dir / \"unmatched_left_nodes.csv\")\n",
    "\n",
    "\n",
    "right_adj = pd.DataFrame(\n",
    "    data=right_adj.astype(int), index=right_nodes.index, columns=right_nodes.index\n",
    ")\n",
    "right_g = nx.from_pandas_adjacency(right_adj, create_using=nx.DiGraph)\n",
    "\n",
    "if RESAVE:\n",
    "    nx.write_edgelist(\n",
    "        right_g,\n",
    "        output_dir / \"unmatched_right_edgelist.csv\",\n",
    "        delimiter=\",\",\n",
    "        data=[\"weight\"],\n",
    "    )\n",
    "    right_nodes.to_csv(output_dir / \"unmatched_right_nodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830e180",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Matched data\n",
    "Next, we consider a left/right hemisphere dataset where we require each neuron in the\n",
    "left hemisphere to be matched with a neuron in the right hemisphere. These pairings\n",
    "were determined by matching both connectivity and morphology in previous publications.\n",
    "\n",
    "Not all neurons in the original dataset were matched, so there will be slightly fewer\n",
    "neurons in this version of the data. Since we have this matched requirement, both\n",
    "networks will necessarily be of the same size.\n",
    "\n",
    "All other aspects of the networks (unweighted, directed, no loops) are the same as\n",
    "described above for the unmatched networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15adab32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:39:36.868118Z",
     "iopub.status.busy": "2022-04-13T20:39:36.867536Z",
     "iopub.status.idle": "2022-04-13T20:40:14.639843Z",
     "shell.execute_reply": "2022-04-13T20:40:14.640375Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "1229"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-n_left_matched"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "1229"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "define_data-n_right_matched"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mg = load_maggot_graph()\n",
    "mg = select_nice_nodes(mg)\n",
    "left_mg, right_mg = mg.bisect(lcc=True, paired=True)\n",
    "left_nodes = left_mg.nodes\n",
    "right_nodes = right_mg.nodes\n",
    "\n",
    "left_adj = left_mg.sum.adj\n",
    "right_adj = right_mg.sum.adj\n",
    "\n",
    "left_adj = binarize(left_adj)\n",
    "right_adj = binarize(right_adj)\n",
    "\n",
    "left_adj = remove_loops(left_adj)\n",
    "right_adj = remove_loops(right_adj)\n",
    "\n",
    "n_left_matched = left_adj.shape[0]\n",
    "n_right_matched = right_adj.shape[0]\n",
    "\n",
    "glue(\"n_left_matched\", n_left_matched)\n",
    "glue(\"n_right_matched\", n_right_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785d1d2",
   "metadata": {},
   "source": [
    "For the matched networks, we are left with {glue:text}`n_left_matched` neurons in the\n",
    "left\n",
    "hemisphere, and {glue:text}`n_right_matched` neurons in the right hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4676c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:40:14.645850Z",
     "iopub.status.busy": "2022-04-13T20:40:14.645208Z",
     "iopub.status.idle": "2022-04-13T20:40:15.256394Z",
     "shell.execute_reply": "2022-04-13T20:40:15.256815Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "left_adj = pd.DataFrame(data=left_adj, index=left_nodes.index, columns=left_nodes.index)\n",
    "left_g = nx.from_pandas_adjacency(left_adj, create_using=nx.DiGraph)\n",
    "if RESAVE:\n",
    "    nx.write_edgelist(\n",
    "        left_g, output_dir / \"matched_left_edgelist.csv\", delimiter=\",\", data=False\n",
    "    )\n",
    "\n",
    "    left_nodes.to_csv(output_dir / \"matched_left_nodes.csv\")\n",
    "\n",
    "\n",
    "right_adj = pd.DataFrame(\n",
    "    data=right_adj, index=right_nodes.index, columns=right_nodes.index\n",
    ")\n",
    "right_g = nx.from_pandas_adjacency(right_adj, create_using=nx.DiGraph)\n",
    "\n",
    "if RESAVE:\n",
    "    nx.write_edgelist(\n",
    "        right_g, output_dir / \"matched_right_edgelist.csv\", delimiter=\",\", data=False\n",
    "    )\n",
    "    right_nodes.to_csv(output_dir / \"matched_right_nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56eb9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T20:40:15.260513Z",
     "iopub.status.busy": "2022-04-13T20:40:15.259918Z",
     "iopub.status.idle": "2022-04-13T20:40:15.301738Z",
     "shell.execute_reply": "2022-04-13T20:40:15.302206Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script took 0:01:02.238273\n",
      "Completed at 2022-04-13 16:40:15.298417\n"
     ]
    }
   ],
   "source": [
    "elapsed = time.time() - t0\n",
    "delta = datetime.timedelta(seconds=elapsed)\n",
    "print(f\"Script took {delta}\")\n",
    "print(f\"Completed at {datetime.datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
